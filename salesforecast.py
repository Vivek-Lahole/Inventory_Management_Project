# -*- coding: utf-8 -*-
"""Salesforecast.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1soL9N_9BJl3hx5MRWlK_B3Ig8-5Mfn6g
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from pylab import rcParams
import seaborn as sns
from statsmodels.tsa.seasonal import seasonal_decompose,STL
from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt
from statsmodels.tsa.stattools import adfuller
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_percentage_error
import pickle
from flask import Flask, render_template,request
import warnings




df=pd.read_csv('Date and model wise sale.csv')

df.head()

df.iloc[::-1].head()

df['Date']=pd.to_datetime(df['Date'])

df=df.groupby('Date')['Count'].count().reset_index()

df.isnull().sum()

df.info()

df.head()

df=df.groupby([df['Date'].dt.year,df['Date'].dt.month]).sum().reset_index(drop=True)

timestamp=pd.date_range(start='2014-01-01',end='2016-08-31',freq ='M')
df['Time_Stamp']=timestamp

df.set_index('Time_Stamp',drop=True,inplace=True)

rcParams['figure.figsize']=15,8
df.plot(grid=True)
plt.plot()
df_quarterly_sum = df.resample('Q').sum()
df_quarterly_sum.head()

df_quarterly_sum.plot();
plt.grid()

decomposition=seasonal_decompose(df['Count'],model='additive')
decomposition.plot()

decomposition=seasonal_decompose(df['Count'],model='multiplicative')
decomposition.plot()

df=df.reset_index()

train =df[df['Time_Stamp'].dt.year<2016]
test =df[df['Time_Stamp'].dt.year>=2016]

train=train.set_index('Time_Stamp',drop=True)

test=test.reset_index()

test=test.drop('index',axis=1)

test=test.set_index('Time_Stamp',drop=True)

train['Count'].plot()
test['Count'].plot()
plt.grid()
plt.title('Car Sales Traning and Test data')
plt.xlabel('Year')
plt.ylabel('Sales')
plt.legend(['Training Data','Test Data'],title='Forecast')

print(len(train))
print(len(test))

train_time = [i+1 for i in range(len(train))]
test_time = [i+25 for i in range(len(test))]
print('Training Time instance','\n',train_time)
print('Test Time instance','\n',test_time)

train['instance']=train_time

test['instance']=test_time

test

from sklearn.linear_model import LinearRegression

lr = LinearRegression()

lr.fit(np.array(train['instance']).reshape(-1,1),train['Count'].values)

predictions=lr.predict(np.array(test['instance']).reshape(-1,1))

train.head()

test['predictions_reg']=predictions

test

plt.figure(figsize=(13,6))
plt.plot(train['Count'],label='Train')
plt.plot(test['Count'],label='Test')
plt.plot(test['predictions_reg'],label='Regression On Time_Test Data')
plt.legend(loc='best')
plt.grid()

from sklearn import metrics

rmse_model1_test=metrics.mean_squared_error(test['Count'],test['predictions_reg'],squared=False)
print("For RegressionOnTime forecast on the Test Data,  RMSE is %3.3f" %(rmse_model1_test))

resultsDf=pd.DataFrame({'Test RMSE': [rmse_model1_test]},index=['RegressionOnTime'])
resultsDf

MovingAverage=df.copy()
MovingAverage.head()

MovingAverage['Trailing_2']=MovingAverage['Count'].rolling(2).mean()
MovingAverage['Trailing_4']=MovingAverage['Count'].rolling(4).mean()
MovingAverage['Trailing_6']=MovingAverage['Count'].rolling(6).mean()
MovingAverage['Trailing_9']=MovingAverage['Count'].rolling(9).mean()

MovingAverage.tail()

plt.plot(MovingAverage['Count'], label='Train')
plt.plot(MovingAverage['Trailing_2'], label='2 Point Moving Average')
plt.plot(MovingAverage['Trailing_4'], label='4 Point Moving Average')
plt.plot(MovingAverage['Trailing_6'],label = '6 Point Moving Average')
plt.plot(MovingAverage['Trailing_9'],label = '9 Point Moving Average')

plt.legend(loc = 'best')
plt.grid()

trailing_MovingAverage_train=MovingAverage[0:int(len(MovingAverage)*0.75)] 
trailing_MovingAverage_test=MovingAverage[int(len(MovingAverage)*0.75):]

plt.figure(figsize=(16,8))
plt.plot(trailing_MovingAverage_train['Count'], label='Train')
plt.plot(trailing_MovingAverage_test['Count'], label='Test')

plt.plot(trailing_MovingAverage_train['Trailing_2'], label='2 Point Trailing Moving Average on Training Set')
plt.plot(trailing_MovingAverage_train['Trailing_4'], label='4 Point Trailing Moving Average on Training Set')
plt.plot(trailing_MovingAverage_train['Trailing_6'],label = '6 Point Trailing Moving Average on Training Set')
plt.plot(trailing_MovingAverage_train['Trailing_9'],label = '9 Point Trailing Moving Average on Training Set')

plt.plot(trailing_MovingAverage_test['Trailing_2'], label='2 Point Trailing Moving Average on Test Set')
plt.plot(trailing_MovingAverage_test['Trailing_4'], label='4 Point Trailing Moving Average on Test Set')
plt.plot(trailing_MovingAverage_test['Trailing_6'],label = '6 Point Trailing Moving Average on Test Set')
plt.plot(trailing_MovingAverage_test['Trailing_9'],label = '9 Point Trailing Moving Average on Test Set')
plt.legend(loc = 'best')
plt.grid()

rmse_model4_test_2 = metrics.mean_squared_error(trailing_MovingAverage_test['Count'],trailing_MovingAverage_test['Trailing_2'],squared=False)
print("For 2 point Moving Average Model forecast on the Training Data,  RMSE is %3.3f" %(rmse_model4_test_2))

rmse_model4_test_4 = metrics.mean_squared_error(trailing_MovingAverage_test['Count'],trailing_MovingAverage_test['Trailing_4'],squared=False)
print("For 4 point Moving Average Model forecast on the Training Data,  RMSE is %3.3f" %(rmse_model4_test_4))

rmse_model4_test_6 = metrics.mean_squared_error(trailing_MovingAverage_test['Count'],trailing_MovingAverage_test['Trailing_6'],squared=False)
print("For 6 point Moving Average Model forecast on the Training Data,  RMSE is %3.3f" %(rmse_model4_test_6))

rmse_model4_test_9 = metrics.mean_squared_error(trailing_MovingAverage_test['Count'],trailing_MovingAverage_test['Trailing_9'],squared=False)
print("For 9 point Moving Average Model forecast on the Training Data,  RMSE is %3.3f " %(rmse_model4_test_9))

resultsDf_4 = pd.DataFrame({'Test RMSE': [rmse_model4_test_2,rmse_model4_test_4
                                          ,rmse_model4_test_6,rmse_model4_test_9]}
                           ,index=['2pointTrailingMovingAverage','4pointTrailingMovingAverage'
                                   ,'6pointTrailingMovingAverage','9pointTrailingMovingAverage'])

resultsDf = pd.concat([resultsDf,resultsDf_4])
resultsDf

TES_train = train.copy()
TES_test = test.copy()

model_TES = ExponentialSmoothing(TES_train['Count'],trend='add',seasonal='multiplicative',freq='M')

model_TES_autofit = model_TES.fit()

model_TES_autofit.params

TES_test['auto_predict'] = model_TES_autofit.forecast(steps=len(test))
TES_test

plt.figure(figsize=(18,9))
plt.plot(TES_train['Count'], label='Train')
plt.plot(TES_test['Count'], label='Test')

plt.plot(TES_test['auto_predict'], label='TripleExponentialSmoothing predictions on Test Set')


plt.legend(loc='best')
plt.grid()

rmse_model6_test_1 = metrics.mean_squared_error(TES_test['Count'],TES_test['auto_predict'],squared=False)
print("Triple Exponential Smoothing Model forecast on the Test Data,  RMSE is %3.3f" %(rmse_model6_test_1))

resultsDf_8_1 = pd.DataFrame({'Test RMSE': [rmse_model6_test_1]}
                           ,index=['Alpha=0.85,Beta=0,Gamma=0.14,TripleExponentialSmoothing'])

resultsDf = pd.concat([resultsDf, resultsDf_8_1])
resultsDf

DES_train=train.copy()
DES_test=test.copy()

model_DES=Holt(DES_train['Count'])

resultsDf_7 = pd.DataFrame({'Alpha Values':[],'Beta Values':[],'Train RMSE':[],'Test RMSE': []})
resultsDf_7

for i in np.arange(0.3,1.1,0.1):
    for j in np.arange(0.3,1.1,0.1):
        model_DES_alpha_i_j = model_DES.fit(smoothing_level=i,smoothing_slope=j,optimized=False,use_brute=True)
        DES_train['predict',i,j] = model_DES_alpha_i_j.fittedvalues
        DES_test['predict',i,j] = model_DES_alpha_i_j.forecast(steps=12)
        
        rmse_model6_train = metrics.mean_squared_error(DES_train['Count'],DES_train['predict',i,j],squared=False)
        
        rmse_model6_test = metrics.mean_squared_error(DES_test['Count'],DES_test['predict',i,j],squared=False)
        
        resultsDf_7 = resultsDf_7.append({'Alpha Values':i,'Beta Values':j,'Train RMSE':rmse_model6_train
                                          ,'Test RMSE':rmse_model6_test},ignore_index=True )

resultsDf_7

resultsDf_7.sort_values(by=['Test RMSE']).head()

resultsDf_7_1 = pd.DataFrame({'Test RMSE': [resultsDf_7.sort_values(by=['Test RMSE']).values[0][3]]}
                           ,index=['Alpha=1,Beta=0.4,DoubleExponentialSmoothing'])

resultsDf = pd.concat([resultsDf, resultsDf_7_1])
resultsDf

plt.figure(figsize=(18,9))
plt.plot(TES_train['Count'], label='Train')
plt.plot(TES_test['Count'], label='Test')

plt.plot(TES_test['auto_predict'], label='DoubleExponentialSmoothing predictions on Test Set')


plt.legend(loc='best')
plt.grid()

df=df.set_index('Time_Stamp')

dftest = adfuller(df,regression='ct')
print('DF test statistic is %3.3f' %dftest[0])
print('DF test p-value is' ,dftest[1])
print('Number of lags used' ,dftest[2])

plot_acf(df,alpha=0.05)

plot_pacf(df,zero=False,lags=14,alpha=0.05)

TS_Train =df[df.index.year<2016]
TS_Test =df[df.index.year>=2016]

dftest = adfuller(TS_Train,regression='ct')
print('DF test statistic is %3.3f' %dftest[0])
print('DF test p-value is' ,dftest[1])
print('Number of lags used' ,dftest[2])

dftest = adfuller(np.log(TS_Train).diff(2).dropna(),regression='ct')
print('DF test statistic is %3.3f' %dftest[0])
print('DF test p-value is' ,dftest[1])
print('Number of lags used' ,dftest[2])

df_diff=np.log(TS_Train).diff(2)

plot_acf(df_diff,title='Training Data Autocorrelation',missing='drop')
plot_pacf(df_diff.dropna(),title='Training Data Partial Autocorrelation',lags=7,zero=False,method='ywmle')
plt.show()

import itertools
p = q = range(0,4)
d= range(0,3)
pdq = list(itertools.product(p, d, q))
print('Examples of the parameter combinations for the Model')
for i in range(0,len(pdq)):
    print('Model: {}'.format(pdq[i]))

ARIMA_AIC = pd.DataFrame(columns=['param', 'AIC'])
ARIMA_AIC

from statsmodels.tsa.arima.model import ARIMA

for param in pdq:
    ARIMA_model = ARIMA(df_diff.values,order=param).fit()
    print('ARIMA{} - AIC:{}'.format(param,ARIMA_model.aic))
    ARIMA_AIC = ARIMA_AIC.append({'param':param, 'AIC': ARIMA_model.aic}, ignore_index=True)

ARIMA_AIC.sort_values(by='AIC',ascending=True).head()

auto_ARIMA = ARIMA(TS_Train, order=(2,0,3))

results_auto_ARIMA = auto_ARIMA.fit()

print(results_auto_ARIMA.summary())

predicted_auto_ARIMA = results_auto_ARIMA.forecast(steps=len(TS_Test))

rmse = mean_squared_error(TS_Test['Count'],predicted_auto_ARIMA,squared=False)
mape = mean_absolute_percentage_error(TS_Test['Count'],predicted_auto_ARIMA)
print('RMSE:',rmse,'\nMAPE:',mape)

temp_resultsDf = pd.DataFrame({'Test RMSE':rmse}
                           ,index=['ARIMA'])


resultsDf = pd.concat([resultsDf,temp_resultsDf])

resultsDf

plt.figure(figsize=(18,9))
plt.plot(TES_train['Count'], label='Train')
plt.plot(TES_test['Count'], label='Test')

plt.plot(predicted_auto_ARIMA,label='ARIMA on Test Set')


plt.legend(loc='best')
plt.grid()

model_DES=Holt(df['Count'])

fullmodel = model_DES.fit(smoothing_level=1,smoothing_slope=0.4,optimized=False,use_brute=True)

prediction=fullmodel.forecast(steps=4)

df['Count'].plot()
prediction.plot()

prediction

df=pd.DataFrame([prediction[0],prediction[1],prediction[2],prediction[3]])





